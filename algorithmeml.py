# -*- coding: utf-8 -*-
"""algorithmeML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/172uqusR6BwqJJAoZG_GHnMWvBoVAuDYx

# Random_Forest
"""

import os
import zipfile
import numpy as np
import shutil
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import joblib

from google.colab import files

uploaded=files.upload()
zip_path="/content/combined_dataset.zip"
extract_path="/content/combined_dataset"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Dataset extracted to:",extract_path)
print("Classes:",os.listdir(extract_path))

import os
import shutil
from sklearn.model_selection import train_test_split
train_path="/content/train_dataset"
test_path="/content/test_dataset"

# creation folder pour le train et le test datasets
os.makedirs(train_path, exist_ok=True)
os.makedirs(test_path, exist_ok=True)
# list des class dans la dataset
classes=os.listdir(extract_path)
#ta9sim
for class_name in classes:
    class_path=os.path.join(extract_path, class_name)
    if os.path.isdir(class_path):
        all_files=os.listdir(class_path)
        #80% train,20% test
        train_files,test_files=train_test_split(all_files, test_size=0.2,random_state=42)
        os.makedirs(os.path.join(train_path, class_name),exist_ok=True)
        os.makedirs(os.path.join(test_path, class_name),exist_ok=True)
        for file_name in train_files:
            shutil.move(os.path.join(class_path,file_name),os.path.join(train_path,class_name,file_name))
        for file_name in test_files:
            shutil.move(os.path.join(class_path,file_name),os.path.join(test_path,class_name,file_name))

print("Dataset hasbeen split into 'train_dataset'and'test_dataset'")

# charger et prétraiter des images
def load_dataset(directory, target_size=(64, 64)):
    images=[]
    labels=[]
    class_names =sorted(os.listdir(directory))
    class_mapping={name: idx for idx, name in enumerate(class_names)}

    for class_name in class_names:
        class_dir=os.path.join(directory,class_name)
        for img_name in os.listdir(class_dir):
            img_path=os.path.join(class_dir,img_name)
            img=load_img(img_path,target_size=target_size)
            img_array=img_to_array(img)/255.0
            images.append(img_array.flatten())
            labels.append(class_mapping[class_name])

    return np.array(images),np.array(labels),class_names

# load training dataset
train_dir='/content/train_dataset'
X,y,class_names=load_dataset(train_dir)
print(f"Loaded {len(X)} images belonging to {len(class_names)} classes.")

X_train,X_test,y_train,y_test=train_test_split(X, y,test_size=0.2,random_state=42)
print(f"Training samples: {len(X_train)}, Testing samples: {len(X_test)}")

# trainer Random Forest
rf_model=RandomForestClassifier(n_estimators=100,random_state=42)
rf_model.fit(X_train,y_train)
#################################
# enregistrement du model
joblib.dump(rf_model, 'random_forest_model.joblib')
print("Random Forest model saved successfully!")

# Evaluation du test
y_pred = rf_model.predict(X_test)
###########################################
# Métrique
print("Test Accuracy:",accuracy_score(y_test,y_pred))
print("Confusion Matrix:\n",confusion_matrix(y_test,y_pred))
print("Classification Report:",classification_report(y_test,y_pred,target_names=class_names))
############################################
# Plot Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 7))
sns.heatmap(cm,annot=True, fmt='d',cmap='Blues',xticklabels=class_names,yticklabels=class_names)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

test_dir='/content/test_dataset'
X_test_new, y_test_new, _=load_dataset(test_dir)

# Charger le modèle
loaded_rf_model=joblib.load('random_forest_model.joblib')

# Prédire sur le nouvel ensemble de données de test
y_pred_new=loaded_rf_model.predict(X_test_new)

# Evaluate
print("Test Accuracy on New Data:",accuracy_score(y_test_new,y_pred_new))
print("Confusion Matrix:\n",confusion_matrix(y_test_new,y_pred_new))
print("Classification Report:\n",classification_report(y_test_new, y_pred_new,target_names=class_names))

# quelques prédictions
for i in range(5):
    img = X_test_new[i].reshape(64, 64, 3)
    predicted_class = class_names[y_pred_new[i]]
    true_class = class_names[y_test_new[i]]
    plt.imshow(img)
    plt.title(f"True:{true_class},Predicted:{predicted_class}")
    plt.axis('off')
    plt.show()

from google.colab import files

uploaded = files.upload()
print(uploaded)

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import load_img, img_to_array
# distingtion de la classe d'une image
def predict_image_class(image_path, model, class_names):
    # Charger l'image
    img=load_img(image_path, target_size=(64,64))
    img_array=img_to_array(img)
    img_array=img_array/255.0
    img_flat=img_array.reshape(1,-1)

    # Prédire la classe
    prediction = model.predict(img_flat)
    predicted_class = class_names[prediction[0]]
    plt.imshow(img)
    plt.title(f"Classe prédite : {predicted_class}")
    plt.axis('off')
    plt.show()
    return predicted_class

# Exemple
image_path="/content/WIN_20241022_14_21_01_Pro.jpg"
predicted_class=predict_image_class(image_path, rf_model, class_names)
print(f"Classe prédite pour l'image : {predicted_class}")

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# si X_train est un tableau NumPy
if isinstance(X_train,(np.ndarray, np.generic)):
    feature_columns=[f"feature_{i}" for i in range(X_train.shape[1])]
    df=pd.DataFrame(X_train, columns=feature_columns)
else:
    df=X_train.copy()

# Ajouter les étiquettes comme colonne au DataFrame
df['label']=y_train

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Création d'un DataFrame avec des données numériques
data={
    'Feature_1':[0.1, 0.2, 0.3, 0.4, 0.5],
    'Feature_2':[1.1, 1.2, 1.3, 1.4, 1.5],
    'Feature_3':[2.1, 2.2, 2.3, 2.4, 2.5],
    'Feature_4':[3.1, 3.2, 3.3, 3.4, 3.5]
}

df=pd.DataFrame(data)

# matrice de corrélation
corr_matrix=df.corr()

# Affichage de la matrice
plt.figure(figsize=(8,6))
sns.heatmap(corr_matrix,annot=True,cmap='coolwarm',fmt='.2f',linewidths=0.5)
plt.title("Matrice de Corrélation")
plt.show()

# Distribution des classes
sns.histplot(y_train, bins=len(class_names), kde=False)
plt.title("Distribution des classes dans l'ensemble d'entraînement")
plt.xlabel("Classe")
plt.ylabel("Nombre d'échantillons")
plt.xticks(ticks=range(len(class_names)), labels=class_names, rotation=45)
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# Réduction de dimensions pour visualisation
small_df = pd.DataFrame(X_train[:, :4], columns=['Feature1','Feature2','Feature3','Feature4'])
small_df['label'] = y_train
# Pairplot
sns.pairplot(small_df, hue='label', palette='bright')
plt.suptitle("Pairplot des 4 premières caractéristiques")
plt.show()

# Boxplot
df = pd.DataFrame(X_train,columns=[f'Feature{i+1}' for i in range(X_train.shape[1])])
df['label']=y_train
feature_index=0
df['Feature']=X_train[:,feature_index]
sns.boxplot(x='label',y='Feature',data=df,palette='Set2')
plt.title(f"Boxplot de la caractéristique {feature_index + 1} par classe")
plt.xlabel("Classe")
plt.ylabel("Valeur")
plt.xticks(ticks=range(len(class_names)),labels=class_names,rotation=45)
plt.show()

# Countplot
sns.countplot(x='label', data=df, palette='pastel')
plt.title("Nombre d'images par classe dans l'ensemble d'entraînement")
plt.xlabel("Classe")
plt.ylabel("Nombre d'images")
plt.xticks(ticks=range(len(class_names)), labels=class_names, rotation=45)
plt.show()

from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
import numpy as np
import os
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split

# fonction pour charger et prétraiter des images
def load_dataset(directory, target_size=(64, 64)):
    images=[]
    labels=[]
    class_names=sorted(os.listdir(directory))
    class_mapping={name: idx for idx, name in enumerate(class_names)}

    for class_name in class_names:
        class_dir=os.path.join(directory, class_name)
        for img_name in os.listdir(class_dir):
            img_path=os.path.join(class_dir, img_name)
            img=load_img(img_path, target_size=target_size)
            img_array=img_to_array(img)/255.0
            images.append(img_array.flatten())
            labels.append(class_mapping[class_name])

    return np.array(images),np.array(labels),class_names

# charger les données d'entraînement
train_dir='/content/train_dataset'
X, y, class_names=load_dataset(train_dir)
print(f"Loaded {len(X)} images belonging to {len(class_names)} classes.")

# diviser l'ensemble de données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"Training samples: {len(X_train)}, Testing samples: {len(X_test)}")

# initialiser le modèle Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Validation croisée avec 4 plis (CV=4)
cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)
cross_val_scores = cross_val_score(rf_model, X_train, y_train, cv=cv)

print("Cross-validation scores:", cross_val_scores)
print(f"Mean cross-validation score: {cross_val_scores.mean()}")

# entraîner le modèle sur l'ensemble d'entraînement complet
rf_model.fit(X_train, y_train)

# sauvegarder le modèle entraîné
joblib.dump(rf_model, 'random_forest_model.joblib')
print("Random Forest model saved successfully!")

# evaluation sur l'ensemble de test
y_pred = rf_model.predict(X_test)

# afficher les métriques
print("Test Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred, target_names=class_names))

# Afficher la matrice de confusion
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""#CNN"""

from google.colab import files
uploaded = files.upload()

import zipfile
import os

zip_path = "/content/combined_dataset.zip"
extract_path = "/content/combined_dataset"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Dossier extrait avec succès !")
print(os.listdir(extract_path))

import os
import shutil
from sklearn.model_selection import train_test_split
train_path = "/content/train_dataset"
test_path = "/content/test_dataset"

# creation folder pour le train et le test datasets
os.makedirs(train_path, exist_ok=True)
os.makedirs(test_path, exist_ok=True)

# list des class dans la dataset
classes = os.listdir(extract_path)
#ta9sim
for class_name in classes:
    class_path = os.path.join(extract_path, class_name)

    if os.path.isdir(class_path):

        all_files = os.listdir(class_path)

        #80% train, 20% test
        train_files, test_files = train_test_split(all_files, test_size=0.2, random_state=42)

        os.makedirs(os.path.join(train_path, class_name), exist_ok=True)
        os.makedirs(os.path.join(test_path, class_name), exist_ok=True)

        for file_name in train_files:
            shutil.move(os.path.join(class_path, file_name), os.path.join(train_path, class_name, file_name))

        for file_name in test_files:
            shutil.move(os.path.join(class_path, file_name), os.path.join(test_path, class_name, file_name))

print("Dataset has been split into 'train_dataset' and 'test_dataset'.")

import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# les transformations
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

dataset = datasets.ImageFolder(root="/content/train_dataset", transform=transform)
print(dataset.classes)
#creation un DataLoader
train_loader = DataLoader(dataset, batch_size=32, shuffle=True)
#affichage
print(f"Nombre total d'images : {len(dataset)}")
print(f"Classes disponibles : {dataset.classes}")

import torch
import torch.nn as nn
import torch.nn.functional as F

# Définir le modèle CNN
class CNNModel(nn.Module):
    def __init__(self, num_classes):
        super(CNNModel, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(32 * 32 * 32, 128)
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 32 * 32 * 32)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# nombre de class initiale
num_classes = len(dataset.classes)
model = CNNModel(num_classes)
print(model)

import torch.optim as optim
criterion = nn.CrossEntropyLoss()  # Fonction de perte pour la classification multi-classes
optimizer = optim.Adam(model.parameters(), lr=0.001)

# GPU est disponible?
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# entraînement
num_epochs = 1
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"Époque {epoch + 1}/{num_epochs}, Perte: {running_loss / len(train_loader):.4f}")

# Sauvegarder le modèle
torch.save(model.state_dict(), "cnn_model.pth")

from google.colab import files
uploaded = files.upload()
print(uploaded)

from PIL import Image
import torch
from torchvision import transforms

print(dataset.classes)

# Affiche les classes et les indices
for idx, class_name in enumerate(dataset.classes):
    print(f"Classe {idx+1}: {class_name}")

# Fonction de prédiction
def predict_image(image_path, model, transform):
    model.eval()
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        output = model(image)
        _, predicted = torch.max(output, 1)
    return dataset.classes[predicted.item()]

# test model sur une image téléchargée
image_path = "photo_5951 6739350.jpg"
predicted_class = predict_image(image_path, model, transform)
print(f"L'image appartient à la classe : {predicted_class}")

from sklearn.metrics import confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

# collection des predictions et labels
all_predictions = []
all_labels = []

model.eval() #le model est en mode evaluation
with torch.no_grad():
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)

        all_predictions.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# calcul de la précision, rappel et F1-score pour chaque classe
from sklearn.metrics import classification_report

report = classification_report(all_labels, all_predictions, target_names=dataset.classes)
print("Classification Report:\n", report)

#matrice confusion
cm = confusion_matrix(all_labels, all_predictions)
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=dataset.classes, yticklabels=dataset.classes)
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

import torch
import torchvision
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image

# 2. les transformations
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# 3. dataset de test
dataset_path = "test_dataset"
test_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# 4. charger le modele entraîné
model = CNNModel(num_classes=len(test_dataset.classes))
model.load_state_dict(torch.load("cnn_model.pth"))
model.to(device)
model.eval()

# 5. Prédictions de jeu de données de test
correct = 0
total = 0

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        # prédictions
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)

        # calcul de la précision
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

accuracy = correct / total
print(f"Précision sur le jeu de données de test : {accuracy * 100:.2f}%")

# des prédictions pour quelques exemples
def imshow(img):
    img = img / 2 + 0.5
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

# quelques images de test et leurs prédictions
data_iter = iter(test_loader)
images, labels = next(data_iter)

#images
imshow(torchvision.utils.make_grid(images))
# prédictions
_, predicted = torch.max(model(images.to(device)), 1)
print(f"Prédictions: {[test_dataset.classes[i] for i in predicted]}")
print(f"Labels: {[test_dataset.classes[i] for i in labels]}")

# matrice de corrélation

with torch.no_grad():
    outputs_all = []
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        outputs_all.append(outputs.cpu().numpy())

outputs_all = np.concatenate(outputs_all, axis=0)
correlation_matrix = np.corrcoef(outputs_all.T)
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', xticklabels=test_dataset.classes, yticklabels=test_dataset.classes)
plt.title("Matrice de corrélation des prédictions")
plt.show()

#histogramme des prédictions
plt.figure(figsize=(10, 6))
sns.histplot(all_predictions, kde=True, bins=len(test_dataset.classes))
plt.xlabel("Classe")
plt.ylabel("Nombre d'occurrences")
plt.title("Histogramme des prédictions")
plt.show()

# des listes pour stocker les sorties, labels et prédictions
outputs_all = []
all_labels = []
all_predictions = []

from sklearn.decomposition import PCA
import pandas as pd

# Évaluation du modèle
with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)

        outputs_all.append(outputs.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())
        all_predictions.extend(predicted.cpu().numpy())

outputs_all = np.concatenate(outputs_all, axis=0)

# vérifier la taille des variables
print(f"Taille de outputs_all : {outputs_all.shape}")
print(f"Taille de all_labels : {len(all_labels)}")
print(f"Taille de all_predictions : {len(all_predictions)}")

if len(all_labels) == outputs_all.shape[0] == len(all_predictions):
    pca = PCA(n_components=2)
    outputs_2d = pca.fit_transform(outputs_all)

    # creation d'un DataFrame pour la visualisation
    df = pd.DataFrame(outputs_2d, columns=['PC1', 'PC2'])
    df['Label'] = all_labels
    df['Prédiction'] = all_predictions

    # affichage du pairplot
    sns.pairplot(df, hue='Label', palette="coolwarm", plot_kws={'alpha': 0.6, 's': 40})
    plt.title("Pairplot des résultats avec PCA")
    plt.show()
else:
    print("Erreur : Les tailles des données ne correspondent pas. Vérifiez les longueurs.")

# boxplot des prédictions
plt.figure(figsize=(10, 6))
sns.boxplot(x=all_labels, y=outputs_all.max(axis=1))
plt.xlabel("Labels réels")
plt.ylabel("Score maximum de la prédiction")
plt.title("Boxplot des scores maximaux de prédiction par classe")
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# countplot
plt.figure(figsize=(10, 6))
sns.countplot(x=all_predictions, palette='coolwarm')
plt.title("Distribution des Prédictions")
plt.xlabel("Classes")
plt.ylabel("Nombre d'exemples")
plt.show()

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
import torch.optim as optim
import numpy as np

# définir la validation croisée (4 plis)
num_folds = 4
skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)

# liste pour stocker les précisions pour chaque pli
fold_accuracies = []

# validation croisée 4 plis
for fold, (train_idx, val_idx) in enumerate(skf.split(np.arange(len(dataset)), dataset.targets)):
    print(f"\nEntraînement et validation pour le pli {fold + 1}/{num_folds}...")

    # créer des sous-ensembles pour l'entraînement et la validation
    train_subset = torch.utils.data.Subset(dataset, train_idx)
    val_subset = torch.utils.data.Subset(dataset, val_idx)

    # chargeurs de données pour l'entraînement et la validation
    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)

    # réinitialiser le modèle pour chaque pli
    model = CNNModel(num_classes=num_classes).to(device)

    # définir l'optimiseur et la fonction de perte
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        print(f"Époque {epoch + 1}/{num_epochs}, Perte: {running_loss / len(train_loader):.4f}")

    # Évaluer sur l'ensemble de validation
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # Calculer la précision
    fold_accuracy = accuracy_score(all_labels, all_preds)
    fold_accuracies.append(fold_accuracy)
    print(f"Précision pour le pli {fold + 1}: {fold_accuracy:.4f}")

# Calcul de la précision moyenne à travers les plis
mean_accuracy = np.mean(fold_accuracies)
print(f"\nPrécision moyenne à travers {num_folds} plis: {mean_accuracy:.4f}")



"""# ResNet18"""

from google.colab import files
uploaded = files.upload()

import zipfile
import os
zip_path = "/content/combineddataset.zip"
extract_path = "/content/combineddataset"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Dossier extrait avec succès !")
print(os.listdir(extract_path))

import torch
import torch.nn as nn
import torchvision.models as models
from torchvision import transforms, datasets
from torch.utils.data import DataLoader, random_split

class CustomResNet18(nn.Module):
    def __init__(self, num_classes):
        super(CustomResNet18, self).__init__()
        self.base_model = models.resnet18(pretrained=True)
        self.base_model.fc = nn.Linear(self.base_model.fc.in_features, num_classes)

    def forward(self, x):
        return self.base_model(x)

# Définir les transformations
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Charger la dataset
data_dir = "/content/combineddataset"
dataset = datasets.ImageFolder(data_dir, transform=transform)

# entraînement et validation (80%-20%)
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = random_split(dataset, [train_size, test_size])

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# initialisation du modèle
num_classes = len(dataset.classes)
model = CustomResNet18(num_classes=num_classes)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

#entraîner le modèle
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

num_epochs = 25
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"Époque {epoch + 1}/{num_epochs}, Perte : {running_loss / len(train_loader):.4f}")

# sauvegarder le modèle
torch.save(model.state_dict(), "custom_resnet18.pth")

# evaluer le modèle
model.eval()
correct = 0
total = 0

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f"Précision sur le dataset de test : {100 * correct / total:.2f}%")

from google.colab import files
uploaded = files.upload()
print(uploaded)

from PIL import Image
import matplotlib.pyplot as plt

import torchvision.transforms as transforms

def predict_image(image_path, model, class_names):
    # charger l'image
    image = Image.open(image_path).convert("RGB")
    plt.imshow(image)

    # appliquer les mêmes transformations
    transform = transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])


    # transformer l'image
    image_tensor = transform(image).unsqueeze(0)

    # passer l'image dans le modèle
    model.eval()
    with torch.no_grad():
        image_tensor = image_tensor.to(device)
        output = model(image_tensor)
        _, predicted_class = torch.max(output, 1)

    return class_names[predicted_class.item()]
#prediction
image_path = "WIN_20241123_17_21_31_Pro.jpg"

predicted_class = predict_image(image_path, model, dataset.classes)
print(f"La classe prédite est : {predicted_class}")

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
#evaluation
model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        all_preds.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# matrice de confusion
conf_matrix = confusion_matrix(all_labels, all_preds)

plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues",
            xticklabels=dataset.classes,
            yticklabels=dataset.classes)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

print("\nClassification Report:")
print(classification_report(all_labels, all_preds, target_names=dataset.classes))

#histogram  du predicted labels
plt.figure(figsize=(10, 6))
sns.histplot(all_preds, kde=False, color='blue', bins=len(dataset.classes))
plt.title("Distribution des étiquettes prédites")
plt.xlabel("Étiquette prédite")
plt.ylabel("Fréquence")
plt.show()

# histogram du labels reel
plt.figure(figsize=(10, 6))
sns.histplot(all_labels, kde=False, color='red', bins=len(dataset.classes))
plt.title("Distribution des étiquettes réelles")
plt.xlabel("Étiquette réelle")
plt.ylabel("Fréquence")
plt.show()

# boxplot
plt.figure(figsize=(10, 6))
sns.boxplot(x=all_labels, y=all_preds)
plt.title("Boxplot des prédictions par étiquette réelle")
plt.xlabel("Étiquette réelle")
plt.ylabel("Étiquette prédite")
plt.show()

# counplot
plt.figure(figsize=(10, 6))
sns.countplot(x=all_labels, palette="Set2")
plt.title("Distribution des étiquettes réelles")
plt.xlabel("Étiquette réelle")
plt.ylabel("Nombre d'occurrences")
plt.show()

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
import torch.optim as optim

# paramètres pour la validation croisée
num_folds = 4  # Nombre de plis (CV=4)
skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)

fold_accuracies = []

for fold, (train_idx, val_idx) in enumerate(skf.split(np.arange(len(dataset)), dataset.targets)):
    print(f"\nEntraînement et validation pour le pli {fold + 1}/{num_folds}...")

    # créer les sous-ensembles d'entraînement et de validation
    train_subset = torch.utils.data.Subset(dataset, train_idx)
    val_subset = torch.utils.data.Subset(dataset, val_idx)

    # créer des DataLoader pour l'entraînement et la validation
    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)

    # réinitialiser le modèle pour chaque pli
    model = CustomResNet18(num_classes=num_classes).to(device)

    # définir l'optimiseur et la fonction de perte
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # entraînement sur ce pli
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()

            outputs = model(inputs)
            loss = criterion(outputs, labels)

            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        print(f"Époque {epoch + 1}/{num_epochs}, Perte : {running_loss / len(train_loader):.4f}")

    # evaluation sur le set de validation
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # calculer la précision pour ce pli
    fold_accuracy = accuracy_score(all_labels, all_preds)
    fold_accuracies.append(fold_accuracy)
    print(f"Précision pour le pli {fold + 1} : {fold_accuracy:.4f}")

# calculer la précision moyenne
mean_accuracy = np.mean(fold_accuracies)
print(f"\nPrécision moyenne sur les {num_folds} plis : {mean_accuracy:.4f}")